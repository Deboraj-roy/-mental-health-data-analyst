{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "mount_file_id": "1CaDq6mXhf1lvlR5pVKYv4PCz_PJT4Eow",
      "authorship_tag": "ABX9TyNAIYSYqz/6H2eR4oj46NiT",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/Deboraj-roy/-mental-health-data-analyst/blob/main/Clean_Model_Classifications.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# SVM model test with categorical dataset using python\n"
      ],
      "metadata": {
        "id": "53xQ9iV4cyFF"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Support Vector Machines (SVM) can be used for classification and regression. In the case of categorical datasets, SVM is used for classification. If the target variable is categorical, then the problem is known as a classification problem. To use SVM with a categorical dataset in Python, you can use the scikit-learn library.\n",
        "\n",
        "Here's an example of how to use an SVM classifier with a categorical dataset in Python:\n"
      ],
      "metadata": {
        "id": "ZH5VGniodhh4"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: In this example, we're using a linear kernel for the SVM classifier. You can try different kernel functions, such as radial basis function (RBF) or polynomial, to see which one works best for your dataset."
      ],
      "metadata": {
        "id": "xL5Ci9BcdrFd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn import svm\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/CGPA 1.csv\")\n",
        "\n",
        "# Split the dataset into training and testing sets\n",
        "X = df.drop([\"CGPA Category\"], axis=1)\n",
        "y = df[\"CGPA Category\"]\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train the SVM model on the training data\n",
        "clf = svm.SVC(kernel='linear')\n",
        "clf.fit(X_train, y_train)\n",
        "\n",
        "# Make predictions on the test data\n",
        "y_pred = clf.predict(X_test)\n",
        "\n",
        "# Calculate the accuracy of the model\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy:\", accuracy)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a4iHIVKWdiE3",
        "outputId": "85820231-f0c4-47a8-adbc-607f4878ceb2"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.2857142857142857\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# New Section csv to arrf\n"
      ],
      "metadata": {
        "id": "dR-neSByeK7F"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load the CSV file into a pandas DataFrame\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Current-year-of-Study.csv\")\n",
        "\n",
        "# Convert the DataFrame to an ARFF file\n",
        "df.to_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/Current-year-of-Study.arff\", index=False, header=False, sep=',', quoting=None, quotechar='\"')\n"
      ],
      "metadata": {
        "id": "UOM7wn7peNnU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "# J48 model test with categorical dataset using python"
      ],
      "metadata": {
        "id": "IfMldzbPcy1R"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "The J48 algorithm is an implementation of the C4.5 decision tree algorithm in the WEKA machine learning library. To use J48 with a categorical dataset in Python, you can use the WEKA library or the scikit-learn library.\n",
        "\n",
        "Here's an example of how to use J48 with a categorical dataset in Python using the scikit-learn library:"
      ],
      "metadata": {
        "id": "JpjyY3jFd-ty"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: In this example, we're using the entropy criterion for splitting the nodes in the decision tree. You can try using the gini index criterion as well to see which one works better for your dataset."
      ],
      "metadata": {
        "id": "Z1cPEvlyd-z0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.metrics import accuracy_score  \n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "\n",
        "# Load your categorical dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/CGPA.csv')\n",
        "\n",
        "# Encode categorical variables into numerical values\n",
        "le = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == \"object\":\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop(\"CGPA Category\", axis=1)\n",
        "y = df[\"CGPA Category\"]\n",
        "\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "# train_data, test_data, train_labels, test_labels = train_test_split(df.drop('CGPA Category', axis=1), df['CGPA Category'], test_size=0.2)\n",
        "train_data, test_data, train_labels, test_labels = train_test_split(X, y, test_size=0.2)\n",
        "\n",
        "# Train the J48 classifier on the training data\n",
        "j48 = DecisionTreeClassifier(criterion='entropy')\n",
        "j48.fit(train_data, train_labels)\n",
        "\n",
        "# Make predictions on the test data\n",
        "predictions = j48.predict(test_data)\n",
        "\n",
        "# Evaluate the accuracy of the model\n",
        "accuracy = accuracy_score(test_labels, predictions)\n",
        "print(\"Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "umYRqjgBeZl6",
        "outputId": "ee36750f-06b2-4fdf-ab69-cc09f3aee401"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 0.5714285714285714\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Naive Bayes model test with categorical dataset using python"
      ],
      "metadata": {
        "id": "1Jaiv2Cfc0Pe"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Naive Bayes is a probabilistic algorithm that is commonly used for classification problems. To use Naive Bayes with a categorical dataset in Python, you can use the scikit-learn library.\n",
        "\n",
        "Here's an example of how to use Naive Bayes with a categorical dataset in Python:"
      ],
      "metadata": {
        "id": "oXg-ku0ke_NT"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note: In this example, we're using the Gaussian Naive Bayes algorithm. If the features in your dataset are not continuous, you can use the Multinomial Naive Bayes or the Bernoulli Naive Bayes algorithm."
      ],
      "metadata": {
        "id": "hAYpCKOqe_ex"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.naive_bayes import CategoricalNB\n",
        "from sklearn.preprocessing import LabelEncoder \n",
        "from sklearn.metrics import accuracy_score \n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv(\"/content/drive/MyDrive/Colab Notebooks/Data/CGPA.csv\")\n",
        "\n",
        "# Encode categorical variables into numerical values\n",
        "le = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == \"object\":\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "# Split the data into features (X) and target (y)\n",
        "X = df.drop(\"CGPA Category\", axis=1)\n",
        "y = df[\"CGPA Category\"]\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=0)\n",
        "\n",
        "# Train a Naive Bayes model\n",
        "model = CategoricalNB()\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict on the test set\n",
        "y_pred = model.predict(X_test)\n",
        "\n",
        "# Evaluate the model's accuracy\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Accuracy: \", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "rrR9j0Nne_1E",
        "outputId": "7a6b71df-858b-4a17-e695-bb04e563c8ec"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy:  0.42857142857142855\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Artificial neural network classifier model test with categorical dataset using python"
      ],
      "metadata": {
        "id": "sdqqwmDicy9I"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here's an example of how you could create and evaluate a neural network classifier for a categorical dataset in Python using the Keras library:"
      ],
      "metadata": {
        "id": "-1VbcHW4ft-O"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Note that in this example, the dataset.csv file should contain the features and categorical labels of the dataset, with the labels stored in a column named \"label\". Additionally, you may need to adjust the hyperparameters (such as the number of hidden units and the number of epochs) depending on the specific characteristics of your dataset."
      ],
      "metadata": {
        "id": "PLzYClRffuMy"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from keras.utils import to_categorical\n",
        "from keras.models import Sequential\n",
        "from keras.layers import Dense\n",
        "\n",
        "# Load the dataset\n",
        "df = pd.read_csv('/content/drive/MyDrive/Colab Notebooks/Data/CGPA.csv')\n",
        "\n",
        "\n",
        "# Encode categorical variables into numerical values\n",
        "le = LabelEncoder()\n",
        "for col in df.columns:\n",
        "    if df[col].dtype == \"object\":\n",
        "        df[col] = le.fit_transform(df[col])\n",
        "\n",
        "\n",
        "# Split the dataset into features (X) and labels (y)\n",
        "X = df.drop('CGPA Category', axis=1)\n",
        "y = df['CGPA Category']\n",
        "\n",
        "# Encode the categorical labels as integers\n",
        "encoder = LabelEncoder()\n",
        "y_encoded = encoder.fit_transform(y)\n",
        "\n",
        "# Convert the integer-encoded labels to one-hot encodings\n",
        "y_one_hot = to_categorical(y_encoded)\n",
        "\n",
        "# Split the dataset into training and test sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y_one_hot, test_size=0.2, random_state=42)\n",
        "\n",
        "# Build the neural network model\n",
        "model = Sequential()\n",
        "model.add(Dense(32, input_dim=X.shape[1], activation='relu'))\n",
        "model.add(Dense(16, activation='relu'))\n",
        "model.add(Dense(y_one_hot.shape[1], activation='softmax'))\n",
        "\n",
        "# Compile the model\n",
        "model.compile(loss='categorical_crossentropy', optimizer='adam', metrics=['accuracy'])\n",
        "\n",
        "# Train the model\n",
        "model.fit(X_train, y_train, epochs=100, batch_size=32, verbose=0)\n",
        "\n",
        "# Evaluate the model on the test set\n",
        "test_loss, test_accuracy = model.evaluate(X_test, y_test, verbose=0)\n",
        "print('Test accuracy:', test_accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ttoY3XaEf1OW",
        "outputId": "c3a8cec5-bc18-4114-e61c-eeb988d99a78"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Test accuracy: 0.2857142984867096\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "\n",
        "---\n",
        "\n",
        "\n",
        "                                          #  END  # \n",
        "\n",
        "---\n",
        "\n"
      ],
      "metadata": {
        "id": "ijB7nPkic2Cp"
      }
    }
  ]
}